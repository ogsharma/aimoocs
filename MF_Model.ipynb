{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MF_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNaDDMFVZ+inlwC/t5NPupa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ogsharma/aimoocs/blob/master/MF_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEfwR83m6KyY",
        "colab_type": "code",
        "outputId": "09be9342-8959-49a5-816b-2cc7c4eec769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "!pip install tensorflow --upgrade"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzDQW6SanoOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "tf.config.experimental_run_functions_eagerly(True)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sys import stdout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-9lJSkwpEuU",
        "colab_type": "code",
        "outputId": "2f2da01d-bf28-43ea-c58e-0e579171c181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5g963OWe4eJ",
        "colab_type": "code",
        "outputId": "48fcd6b4-ab56-4a66-d512-5c47fdc79cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHCNJcM9noOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "import sklearn\n",
        "import sklearn.manifold\n",
        "import tensorflow as tf\n",
        "\n",
        "# Add some convenience functions to Pandas DataFrame.\n",
        "pd.options.display.max_rows = 100\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "\n",
        "def mask(df, key, function):\n",
        "    \"\"\"Returns a filtered dataframe, by applying function to key\"\"\"\n",
        "    return df[function(df[key])]\n",
        "\n",
        "def flatten_cols(df):\n",
        "    df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
        "    return df\n",
        "\n",
        "pd.DataFrame.mask = mask\n",
        "pd.DataFrame.flatten_cols = flatten_cols"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWbxzOTBnxBl",
        "colab_type": "code",
        "outputId": "c0b26c06-457c-4319-f969-366ddad6159c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')\n",
        "with open('/content/drive/My Drive/user_ratings.csv', 'r') as f:\n",
        "  ratings = pd.read_csv(f)\n",
        "\n",
        "with open('/content/drive/My Drive/job_title_mapping.csv', 'r') as f:\n",
        "    job_title_mapping = pd.read_csv(f)\n",
        "\n",
        "ratings.columns = ['user_id','job_id','rating']\n",
        "\n",
        "## Create User ID and Job ID Mapping (For using a sparse matrix representation)\n",
        "\n",
        "user_id_mapping = {}\n",
        "\n",
        "for idx,uid in enumerate(list(ratings.user_id.unique())):\n",
        "    user_id_mapping[uid] = idx\n",
        "\n",
        "job_id_mapping = {}\n",
        "\n",
        "for idx,uid in enumerate(list(ratings.job_id.unique())):\n",
        "    job_id_mapping[uid] = idx\n",
        "\n",
        "# Applying the new mapping on Users and Jobs\n",
        "\n",
        "ratings.loc[:,'user_id'] = ratings['user_id'].apply(lambda x : user_id_mapping[x])\n",
        "ratings.loc[:,'job_id'] = ratings['job_id'].apply(lambda x : job_id_mapping[x])\n",
        "\n",
        "# Creating a mapping for old Job ID to new Job ID\n",
        "job_title_mapping['new_id'] = job_title_mapping['job_id'].apply(lambda x : job_id_mapping[x])\n",
        "\n",
        "# New column names for job title Dataframe\n",
        "job_title_mapping.columns = ['old_id','title','job_id']\n",
        "\n",
        "#\n",
        "jobs = pd.merge(ratings['job_id'],job_title_mapping[['title','job_id']],on='job_id',how='left')\n",
        "jobs.drop_duplicates(['job_id'],inplace=True)\n",
        "jobs = jobs.reset_index().drop(['index'],axis=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT6H7atZAYsa",
        "colab_type": "code",
        "outputId": "798bdb6a-45fd-4cea-c25c-319093f78932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ratings.sample(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>job_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3133094</th>\n",
              "      <td>110987</td>\n",
              "      <td>256</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1963992</th>\n",
              "      <td>25675</td>\n",
              "      <td>11138</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1629863</th>\n",
              "      <td>35927</td>\n",
              "      <td>896</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748934</th>\n",
              "      <td>21379</td>\n",
              "      <td>15760</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1877859</th>\n",
              "      <td>103115</td>\n",
              "      <td>1490</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         user_id  job_id  rating\n",
              "3133094   110987     256       2\n",
              "1963992    25675   11138       2\n",
              "1629863    35927     896       1\n",
              "748934     21379   15760       1\n",
              "1877859   103115    1490       2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEsEbszsIMwZ",
        "colab_type": "code",
        "outputId": "145c4c94-e5b9-4766-9e6d-ce254a9e77cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "jobs.sample(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_id</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14500</th>\n",
              "      <td>14500</td>\n",
              "      <td>Head - Internal Audit - NBFC (9-16 yrs)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13499</th>\n",
              "      <td>13499</td>\n",
              "      <td>Drip Capital - Manager - Talent Acquisition  (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37404</th>\n",
              "      <td>37404</td>\n",
              "      <td>Chief of Staff/Program Manager - FinTech (7-10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2232</th>\n",
              "      <td>2232</td>\n",
              "      <td>Inventory Manager - Retail Chain (3-6 yrs)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37861</th>\n",
              "      <td>37861</td>\n",
              "      <td>Business Development Manager - Energy/Power Ma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       job_id                                              title\n",
              "14500   14500            Head - Internal Audit - NBFC (9-16 yrs)\n",
              "13499   13499  Drip Capital - Manager - Talent Acquisition  (...\n",
              "37404   37404  Chief of Staff/Program Manager - FinTech (7-10...\n",
              "2232     2232         Inventory Manager - Retail Chain (3-6 yrs)\n",
              "37861   37861  Business Development Manager - Energy/Power Ma..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpwcvUknKAVr",
        "colab_type": "text"
      },
      "source": [
        "## Helper Functions for the Matrix Factorization Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "5GYWUp9RnoOf",
        "colab_type": "code",
        "outputId": "32583902-a1a7-46ee-9634-228803b19f86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print((ratings.user_id.nunique()))\n",
        "print(ratings.job_id.nunique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "137372\n",
            "42640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77e6uC3_noOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_rating_sparse_tensor(ratings_df):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    ratings_df: a pd.DataFrame with `user_id`, `movie_id` and `rating` columns.\n",
        "    Returns:\n",
        "    A tf.SparseTensor representing the ratings matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    indices = ratings_df[['user_id','job_id']].values\n",
        "    values = ratings_df['rating'].values\n",
        "\n",
        "    return tf.SparseTensor(\n",
        "      indices=indices,\n",
        "      values=values,\n",
        "      dense_shape=[ratings.user_id.nunique(), ratings.job_id.nunique()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMMrxD-KetwF",
        "colab_type": "code",
        "outputId": "26bb7550-af0d-4fc3-dc12-5e8073935e26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPbg7X5MnoOm",
        "colab_type": "text"
      },
      "source": [
        "### Implementation of the Loss function in TensorFlow\n",
        "\n",
        "Regular Mean Square and its faster implementation for larger data size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRWkMH-BsfhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_dataframe(df, holdout_fraction=0.1):\n",
        "    \"\"\"Splits a DataFrame into training and test sets.\n",
        "    Args:\n",
        "    df: a dataframe.\n",
        "    holdout_fraction: fraction of dataframe rows to use in the test set.\n",
        "    Returns:\n",
        "    train: dataframe for training\n",
        "    test: dataframe for testing\n",
        "    \"\"\"\n",
        "    test = df.sample(frac=holdout_fraction, replace=False)\n",
        "    train = df[~df.index.isin(test.index)]\n",
        "    return train, test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGLon7--P1-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sparse_mean_square_error(sparse_ratings, user_embeddings, job_embeddings):\n",
        "    \n",
        "    \"\"\"\n",
        "    Args:\n",
        "    sparse_ratings: A SparseTensor rating matrix, of dense_shape [N, M]\n",
        "    user_embeddings: A dense Tensor U of shape [N, k] where k is the embedding\n",
        "      dimension, such that U_i is the embedding of user i.\n",
        "    job_embeddings: A dense Tensor V of shape [M, k] where k is the embedding\n",
        "      dimension, such that V_j is the embedding of job j.\n",
        "    Returns:\n",
        "    A scalar Tensor representing the MSE between the true ratings and the\n",
        "      model's predictions.\n",
        "    \"\"\"\n",
        "    \n",
        "    u_ = tf.gather(user_embeddings, sparse_ratings.indices[:, 0])\n",
        "    v_ = tf.gather(job_embeddings, sparse_ratings.indices[:, 1])\n",
        "    \n",
        "    predictions = tf.reduce_sum(u_*v_ ,axis=1)\n",
        "\n",
        "    loss = tf.losses.mean_squared_error(sparse_ratings.values, predictions)\n",
        "    \n",
        "    # loss = tf.keras.losses.MeanSquaredError(sparse_ratings.values, predictions)\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-zMiaslnoOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse_loss(sparse_ratings, user_embeddings, job_embeddings):\n",
        "\n",
        "    u_ = tf.gather(user_embeddings, sparse_ratings.indices[:, 0])\n",
        "    v_ = tf.gather(job_embeddings, sparse_ratings.indices[:, 1])\n",
        "    \n",
        "    predictions = tf.reduce_sum(u_*v_ ,axis=1)\n",
        "\n",
        "    loss = tf.losses.mean_squared_error(sparse_ratings.values, predictions)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# embedding_dim=3\n",
        "# init_stddev=1.\n",
        "\n",
        "# train_ratings, test_ratings = split_dataframe(ratings)\n",
        "\n",
        "# A_train = build_rating_sparse_tensor(train_ratings)\n",
        "# A_test = build_rating_sparse_tensor(test_ratings)\n",
        "\n",
        "# U = tf.Variable(tf.random.normal(\n",
        "#     [A_train.dense_shape[0], embedding_dim], stddev=init_stddev),trainable=True)\n",
        "# V = tf.Variable(tf.random.normal(\n",
        "#     [A_train.dense_shape[1], embedding_dim], stddev=init_stddev),trainable=True)\n",
        "\n",
        "# train_loss = sparse_mean_square_error(A_train, U, V)\n",
        "# test_loss = sparse_mean_square_error(A_test, U, V)\n",
        "\n",
        "\n",
        "# optimizer = tf.keras.optimizers.SGD(learning_rate=20)\n",
        "\n",
        "# for _ in range(100):\n",
        "\n",
        "#     var_list = [U,V]\n",
        "\n",
        "#     with tf.GradientTape() as tape:\n",
        "#         train_error = mse_loss(A_train, U, V)\n",
        "#         test_error = mse_loss(A_test, U, V)\n",
        "\n",
        "#     print('Test Error = {:.2f}, Train Error = {:.2f}'.format(test_error.numpy(), train_error.numpy()))\n",
        "\n",
        "#     grads = tape.gradient(train_error,var_list)\n",
        "#     processed_gradients = [g for g in grads]\n",
        "\n",
        "#     zipped_vars = zip(processed_gradients,var_list)\n",
        "\n",
        "#     # print('grads0 = {:.1f}, grads1 = {:.1f} '.format( grads[0].numpy(), grads[1].numpy()))\n",
        "#     # print(grads[0])\n",
        "#     optimizer.apply_gradients(zipped_vars)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9voly33NnMSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MFModel(object):\n",
        "\n",
        "    def __init__(self, ratings_df, learning_rate=20., gravity_coeff=1., \n",
        "                 init_stddev=1., embedding_dim=3, regularization_coeff=0.1, num_iterations=100, metrics=None, optimizer='sgd'):\n",
        "        \n",
        "        self.U = None\n",
        "        self.V = None\n",
        "        self.ratings_df = ratings_df\n",
        "        self.init_stddev = init_stddev\n",
        "        self.learning_rate = learning_rate\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.gravity_coeff = gravity_coeff\n",
        "        self.regularization_coeff = regularization_coeff \n",
        "        self.num_iterations = num_iterations\n",
        "        self.optimizer = optimizer\n",
        "        self.error_tracker = {'iteration':[], 'test_error':[], 'train_error': []}\n",
        "        \n",
        "    @property\n",
        "    def embeddings(self):\n",
        "\n",
        "        \"\"\"\n",
        "        Returns embeddings for Users and Jobs\n",
        "        \"\"\"\n",
        "        embeddings_dict = {'user_id' : self.U, 'job_id' : self.V}\n",
        "\n",
        "        return embeddings_dict\n",
        "\n",
        "    def optimizer_selection(self, optimizer):\n",
        "\n",
        "        opt_dict = {'sgd' : tf.keras.optimizers.SGD(learning_rate=self.learning_rate),\n",
        "                    'adam' : tf.keras.optimizers.Adam(learning_rate=self.learning_rate),\n",
        "                    'adagrad' : tf.keras.optimizers.Adagrad(learning_rate=self.learning_rate),\n",
        "                    'adadelta' : tf.keras.optimizers.Adadelta(learning_rate=self.learning_rate)}\n",
        "\n",
        "        return opt_dict[optimizer]\n",
        "\n",
        "    def build_rating_sparse_tensor(self):\n",
        "\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        ratings_df: a pd.DataFrame with `user_id`, `movie_id` and `rating` columns.\n",
        "        Returns:\n",
        "        A tf.SparseTensor representing the ratings matrix.\n",
        "        \"\"\"\n",
        "\n",
        "        indices = self.ratings_df[['user_id','job_id']].values\n",
        "        values = self.ratings_df['rating'].values\n",
        "\n",
        "        return tf.SparseTensor(\n",
        "        indices=indices,\n",
        "        values=values,\n",
        "        dense_shape=[self.ratings.user_id.nunique(), self.ratings.job_id.nunique()])\n",
        "\n",
        "    def gravity(self, U, V):\n",
        "\n",
        "        \"\"\"Creates a gravity loss given two embedding matrices.\"\"\"\n",
        "\n",
        "        return 1. / (U.shape[0].value*V.shape[0].value) * tf.reduce_sum(\n",
        "        tf.matmul(U, U, transpose_a=True) * tf.matmul(V, V, transpose_a=True))\n",
        "\n",
        "\n",
        "    def sparse_mean_square_error(self, sparse_ratings, user_embeddings, job_embeddings):\n",
        "    \n",
        "        \"\"\"\n",
        "        Args:\n",
        "        sparse_ratings: A SparseTensor rating matrix, of dense_shape [N, M]\n",
        "        user_embeddings: A dense Tensor U of shape [N, k] where k is the embedding\n",
        "        dimension, such that U_i is the embedding of user i.\n",
        "        job_embeddings: A dense Tensor V of shape [M, k] where k is the embedding\n",
        "        dimension, such that V_j is the embedding of job j.\n",
        "        Returns:\n",
        "        A scalar Tensor representing the MSE between the true ratings and the\n",
        "        model's predictions.\n",
        "        \"\"\"\n",
        "        \n",
        "        u_ = tf.gather(user_embeddings, sparse_ratings.indices[:, 0])\n",
        "        v_ = tf.gather(job_embeddings, sparse_ratings.indices[:, 1])\n",
        "        \n",
        "        predictions = tf.reduce_sum(u_*v_ ,axis=1)\n",
        "        loss = tf.losses.mean_squared_error(sparse_ratings.values, predictions)\n",
        "        \n",
        "        return loss\n",
        "\n",
        "    @tf.function\n",
        "    def train_process(self, train_data, test_data):\n",
        "\n",
        "        optimizer = self.optimizer_selection(self.optimizer)\n",
        "        print('Optimizer : ',self.optimizer,' ')\n",
        "\n",
        "        for i in range(self.num_iterations+1):\n",
        "\n",
        "            var_list = [self.U, self.V]\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                observed_loss = self.regularized_loss(train_data, self.U, self.V)\n",
        "                test_error = self.sparse_mean_square_error(test_data, self.U, self.V)\n",
        "                train_error = self.sparse_mean_square_error(train_data, self.U, self.V)\n",
        "\n",
        "            grads = tape.gradient(observed_loss ,var_list)\n",
        "            processed_gradients = [g for g in grads]\n",
        "\n",
        "            zipped_vars = zip(processed_gradients,var_list)\n",
        "            optimizer.apply_gradients(zipped_vars)\n",
        "\n",
        "            print('\\r', 'Iteration : ', i, 'Test Error : ', test_error.numpy(), 'Train Error : ', train_error.numpy(), 'Observed Loss', observed_loss.numpy(), ' ', end='')\n",
        "            \n",
        "            self.error_tracker['iteration'].append(i)\n",
        "            self.error_tracker['test_error'].append(test_error.numpy())\n",
        "            self.error_tracker['train_error'].append(train_error.numpy())\n",
        "\n",
        "\n",
        "    def gravity(self, U, V):\n",
        "\n",
        "        \"\"\"Creates a gravity loss given two embedding matrices.\"\"\"\n",
        "\n",
        "        return 1. / (U.shape[0]*V.shape[0]) * tf.reduce_sum(\n",
        "        tf.matmul(U, U, transpose_a=True) * tf.matmul(V, V, transpose_a=True))\n",
        "\n",
        "    def regularized_loss(self, sparse_ratings, user_embeddings, job_embeddings):\n",
        "\n",
        "        A_train = sparse_ratings\n",
        "        U = user_embeddings\n",
        "        V = job_embeddings\n",
        "\n",
        "        error_train = self.sparse_mean_square_error(A_train, U, V)\n",
        "        gravity_loss = self.gravity_coeff*self.gravity(U, V)\n",
        "        \n",
        "        regularization_loss = self.regularization_coeff * (\n",
        "            tf.reduce_sum(U*U)/U.shape[0] + tf.reduce_sum(V*V)/V.shape[0])\n",
        "\n",
        "        total_loss = error_train + regularization_loss + gravity_loss\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "    def split_dataframe(self, df, holdout_fraction=0.1):\n",
        "        \"\"\"Splits a DataFrame into training and test sets.\n",
        "        Args:\n",
        "        df: a dataframe.\n",
        "        holdout_fraction: fraction of dataframe rows to use in the test set.\n",
        "        Returns:\n",
        "        train: dataframe for training\n",
        "        test: dataframe for testing\n",
        "        \"\"\"\n",
        "        test = df.sample(frac=holdout_fraction, replace=False)\n",
        "        train = df[~df.index.isin(test.index)]\n",
        "        return train, test\n",
        "        \n",
        "    def train(self):\n",
        "\n",
        "        train_ratings, test_ratings = split_dataframe(self.ratings_df)\n",
        "\n",
        "        A_train = build_rating_sparse_tensor(train_ratings)\n",
        "        A_test = build_rating_sparse_tensor(test_ratings)\n",
        "\n",
        "        # A_train, A_test = self.split_dataframe()\n",
        "        \n",
        "        self.U = tf.Variable(tf.random.normal(\n",
        "      [A_train.dense_shape[0], self.embedding_dim], stddev=self.init_stddev))\n",
        "       \n",
        "        self.V = tf.Variable(tf.random.normal(\n",
        "        [A_train.dense_shape[1], self.embedding_dim], stddev=self.init_stddev))\n",
        "        \n",
        "        self.train_process(A_train, A_test)\n",
        "\n",
        "    def plot_error(self):\n",
        "\n",
        "        error_df = pd.DataFrame(self.error_tracker)\n",
        "        plt.plot(error_df['iteration'], error_df['test_error'])\n",
        "        plt.show()\n",
        "\n",
        "    def get_error_dict(self):\n",
        "\n",
        "        return self.error_tracker"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWPGP1LSTtMg",
        "colab_type": "code",
        "outputId": "b11bdc8e-b9de-47c2-abe7-67696f457197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model = MFModel(ratings_df=ratings, num_iterations=10000, embedding_dim=5, optimizer='adagrad')\n",
        "model.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer :  adagrad  \n",
            " Iteration :  10000 Test Error :  0.3374283 Train Error :  0.27557376 Observed Loss 0.5496093  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKvQXb0Rxotl",
        "colab_type": "code",
        "outputId": "0cb331e1-5307-4def-caf5-2abc10ba6921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "model.plot_error()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD4CAYAAAAqw8chAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUFiLiJQBhbWISBlQWIuIlAGFtYhIGfh/7xv8Nu4q/z8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeF_ggxse8Us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STy4305vKqcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = {}\n",
        "\n",
        "params = {'embedding_dim':[25,30,35,40,50], 'learn_rate':[0.1,5,10,15]}\n",
        "\n",
        "for k,v in params.items():\n",
        "\n",
        "    if k=='embedding_dim':\n",
        "\n",
        "        adadelta_results[k] = {}\n",
        "\n",
        "        for dim in params[k]:\n",
        "            model = MFModel(ratings_df=ratings, num_iterations=2000,embedding_dim=dim,optimizer='adadelta')\n",
        "            model.train()\n",
        "            error_dict = model.get_error_dict()\n",
        "            \n",
        "            adadelta_results[k][dim] = np.min(error_dict['test_error'])\n",
        "\n",
        "    else:\n",
        "        continue\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_rpXcIbxrAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}